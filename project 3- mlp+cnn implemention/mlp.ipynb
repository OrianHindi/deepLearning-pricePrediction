{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading house attributes...\n",
      "Iteration: 0  loss: 515004760000.0\n",
      "Iteration: 1000  loss: 161708360000.0\n",
      "Iteration: 2000  loss: 158669390000.0\n",
      "Iteration: 3000  loss: 157838280000.0\n",
      "Iteration: 4000  loss: 156802170000.0\n",
      "Iteration: 5000  loss: 156427530000.0\n",
      "Iteration: 6000  loss: 156496870000.0\n",
      "Iteration: 7000  loss: 156076950000.0\n",
      "Iteration: 8000  loss: 156117240000.0\n",
      "Iteration: 9000  loss: 155986660000.0\n",
      "Iteration: 10000  loss: 155135210000.0\n",
      "Iteration: 11000  loss: 154714300000.0\n",
      "Iteration: 12000  loss: 154210880000.0\n",
      "Iteration: 13000  loss: 152896450000.0\n",
      "Iteration: 14000  loss: 152409750000.0\n",
      "Iteration: 15000  loss: 152201120000.0\n",
      "Iteration: 16000  loss: 150446880000.0\n",
      "Iteration: 17000  loss: 150303650000.0\n",
      "Iteration: 18000  loss: 150616150000.0\n",
      "Iteration: 19000  loss: 149606150000.0\n",
      "Iteration: 20000  loss: 149421110000.0\n",
      "Iteration: 21000  loss: 149164570000.0\n",
      "Iteration: 22000  loss: 148988770000.0\n",
      "Iteration: 23000  loss: 149139010000.0\n",
      "Iteration: 24000  loss: 149662070000.0\n",
      "Iteration: 25000  loss: 149937400000.0\n",
      "Iteration: 26000  loss: 153044400000.0\n",
      "Iteration: 27000  loss: 147805210000.0\n",
      "Iteration: 28000  loss: 141975400000.0\n",
      "Iteration: 29000  loss: 142616600000.0\n",
      "Iteration: 30000  loss: 143482950000.0\n",
      "Iteration: 31000  loss: 144998730000.0\n",
      "Iteration: 32000  loss: 148258300000.0\n",
      "Iteration: 33000  loss: 145421240000.0\n",
      "Iteration: 34000  loss: 143246720000.0\n",
      "Iteration: 35000  loss: 129629590000.0\n",
      "Iteration: 36000  loss: 138076050000.0\n",
      "Iteration: 37000  loss: 138220630000.0\n",
      "Iteration: 38000  loss: 137245600000.0\n",
      "Iteration: 39000  loss: 137017470000.0\n",
      "Iteration: 40000  loss: 137237684000.0\n",
      "Iteration: 41000  loss: 134557065000.0\n",
      "Iteration: 42000  loss: 157151890000.0\n",
      "Iteration: 43000  loss: 156065580000.0\n",
      "Iteration: 44000  loss: 155621870000.0\n",
      "Iteration: 45000  loss: 153887240000.0\n",
      "Iteration: 46000  loss: 153326500000.0\n",
      "Iteration: 47000  loss: 152527520000.0\n",
      "Iteration: 48000  loss: 150028350000.0\n",
      "Iteration: 49000  loss: 146292260000.0\n",
      "Iteration: 50000  loss: 147107070000.0\n",
      "Iteration: 51000  loss: 148377260000.0\n",
      "Iteration: 52000  loss: 145259970000.0\n",
      "Iteration: 53000  loss: 153059360000.0\n",
      "Iteration: 54000  loss: 151214100000.0\n",
      "Iteration: 55000  loss: 149347880000.0\n",
      "Iteration: 56000  loss: 149959870000.0\n",
      "Iteration: 57000  loss: 148013610000.0\n",
      "Iteration: 58000  loss: 148202050000.0\n",
      "Iteration: 59000  loss: 148052620000.0\n",
      "Iteration: 60000  loss: 150964270000.0\n",
      "Iteration: 61000  loss: 149583790000.0\n",
      "Iteration: 62000  loss: 149790920000.0\n",
      "Iteration: 63000  loss: 150450730000.0\n",
      "Iteration: 64000  loss: 150470360000.0\n",
      "Iteration: 65000  loss: 150343250000.0\n",
      "Iteration: 66000  loss: 148318850000.0\n",
      "Iteration: 67000  loss: 148850670000.0\n",
      "Iteration: 68000  loss: 148979060000.0\n",
      "Iteration: 69000  loss: 149646380000.0\n",
      "Iteration: 70000  loss: 149548150000.0\n",
      "Iteration: 71000  loss: 149744060000.0\n",
      "Iteration: 72000  loss: 149066970000.0\n",
      "Iteration: 73000  loss: 150021000000.0\n",
      "Iteration: 74000  loss: 149862760000.0\n",
      "Iteration: 75000  loss: 149391460000.0\n",
      "Iteration: 76000  loss: 148857590000.0\n",
      "Iteration: 77000  loss: 149934930000.0\n",
      "Iteration: 78000  loss: 148778340000.0\n",
      "Iteration: 79000  loss: 149577710000.0\n",
      "Iteration: 80000  loss: 149376350000.0\n",
      "Iteration: 81000  loss: 149486710000.0\n",
      "Iteration: 82000  loss: 148585510000.0\n",
      "Iteration: 83000  loss: 148901500000.0\n",
      "Iteration: 84000  loss: 148698920000.0\n",
      "Iteration: 85000  loss: 148593520000.0\n",
      "Iteration: 86000  loss: 149165030000.0\n",
      "Iteration: 87000  loss: 149580000000.0\n",
      "Iteration: 88000  loss: 147704020000.0\n",
      "Iteration: 89000  loss: 149613020000.0\n",
      "Iteration: 90000  loss: 147552520000.0\n",
      "Iteration: 91000  loss: 149137850000.0\n",
      "Iteration: 92000  loss: 148465240000.0\n",
      "Iteration: 93000  loss: 149750300000.0\n",
      "Iteration: 94000  loss: 149134570000.0\n",
      "Iteration: 95000  loss: 148283770000.0\n",
      "Iteration: 96000  loss: 148870760000.0\n",
      "Iteration: 97000  loss: 149290600000.0\n",
      "Iteration: 98000  loss: 148379630000.0\n",
      "Iteration: 99000  loss: 148865100000.0\n",
      "Iteration: 100000  loss: 148149080000.0\n",
      " Test error: 278744560000.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.core import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import concatenate\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import argparse\n",
    "import locale\n",
    "import os\n",
    "import import_ipynb\n",
    "import house_models\n",
    "import numrical_features\n",
    "import images_features\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "# construct the path to the input .txt file \n",
    "print(\"[INFO] loading house attributes...\")\n",
    "inputPath = \"HousesInfo.txt\"\n",
    "df = numrical_features.load_house_attributes(inputPath)\n",
    "\n",
    "data_y=df['price']\n",
    "data_x=df.drop(['price','zipcode'],axis = 1)\n",
    "data_x_scaled=(data_x-data_x.mean())/data_x.std()#normalization \n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(data_x_scaled,data_y,test_size=0.3,random_state=0)\n",
    "\n",
    "new_x_train=np.array(x_train)\n",
    "new_y_train = np.array(y_train)\n",
    "new_x_test = np.array(x_test)\n",
    "new_y_test = np.array(y_test)\n",
    "\n",
    "new_y_train = new_y_train.reshape(y_train.shape[0],1)\n",
    "new_y_test = new_y_test.reshape(y_test.shape[0],1)\n",
    "\n",
    "learning_rate = 0.0000005\n",
    "features =6\n",
    "hidden1_size=8\n",
    "training_epochs = 100000\n",
    "\n",
    "#pre proccesing..\n",
    "x = tf.placeholder(tf.float32, [None, features])\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "W1 = tf.Variable(tf.truncated_normal([features, hidden1_size], stddev=0.1))\n",
    "b1 = tf.Variable(tf.constant(0.1, shape=[hidden1_size]))\n",
    "z1 = tf.nn.relu(tf.matmul(x,W1)+b1)\n",
    "W2 = tf.Variable(tf.truncated_normal([hidden1_size, 1], stddev=0.1))\n",
    "b2 = tf.Variable(tf.constant(0.1, shape=[1]))\n",
    "\n",
    "y = tf.matmul(z1,W2)+b2\n",
    "\n",
    "loss = tf.reduce_mean(tf.pow(y-y_,2))\n",
    "update = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(0,training_epochs+1):\n",
    "    sess.run(update, feed_dict = {x:new_x_train, y_:new_y_train})\n",
    "    if i%1000==0:\n",
    "        print('Iteration:' , i , ' loss:', loss.eval(session=sess, feed_dict = {x:new_x_train, y_:new_y_train}))\n",
    "print( ' Test error:', loss.eval(session=sess, feed_dict = {x:new_x_test, y_:new_y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'TensorFlow-GPU'",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
